{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. 程序初始化\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import logging\n",
    "import argparse\n",
    "import itertools\n",
    "import numpy as np\n",
    "from random import sample\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack(flat, layers=16):\n",
    "    \"\"\"Convert an [4, 4] representation into [4, 4, layers] with one layers for each value.\"\"\"\n",
    "    # representation is what each layer represents\n",
    "    representation = 2 ** (np.arange(layers, dtype=int) + 1)\n",
    "\n",
    "    # layered is the flat board repeated layers times\n",
    "    layered = np.repeat(flat[:, :, np.newaxis], layers, axis=-1)\n",
    "\n",
    "    # Now set the values in the board to 1 or zero depending whether they match representation.\n",
    "    # Representation is broadcast across a number of axes\n",
    "    layered = np.where(layered == representation, 1, 0)\n",
    "\n",
    "    return layered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. 创建环境\n",
    "def pairwise(iterable):\n",
    "    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
    "    a, b = itertools.tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "class IllegalMove(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 游戏环境\n",
    "class Game2048Env(gym.Env):\n",
    "    metadata = {'render.modes': ['ansi', 'human', 'rgb_array']}\n",
    "\n",
    "    def __init__(self):\n",
    "        # Definitions for game. Board must be square.\n",
    "        self.size = 4\n",
    "        self.w = self.size\n",
    "        self.h = self.size\n",
    "        self.squares = self.size * self.size\n",
    "\n",
    "        # Maintain own idea of game score, separate from rewards\n",
    "        self.score = 0\n",
    "\n",
    "        # Members for gym implementation\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        # Suppose that the maximum tile is as if you have powers of 2 across the board.\n",
    "        layers = self.squares\n",
    "        self.observation_space = spaces.Box(0, 1, (self.w, self.h, layers), int)\n",
    "        self.set_illegal_move_reward(-20)\n",
    "        self.set_max_tile(None)\n",
    "\n",
    "        # Size of square for rendering\n",
    "        self.grid_size = 70\n",
    "\n",
    "        # Initialise seed\n",
    "        self.seed()\n",
    "\n",
    "        # Reset ready for a game\n",
    "        self.reset()\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def set_illegal_move_reward(self, reward):\n",
    "        \"\"\"Define the reward/penalty for performing an illegal move. Also need\n",
    "            to update the reward range for this.\"\"\"\n",
    "        # Guess that the maximum reward is also 2**squares though you'll probably never get that.\n",
    "        # (assume that illegal move reward is the lowest value that can be returned\n",
    "        self.illegal_move_reward = reward\n",
    "        self.reward_range = (self.illegal_move_reward, float(2 ** self.squares))\n",
    "\n",
    "    def set_max_tile(self, max_tile):\n",
    "        \"\"\"Define the maximum tile that will end the game (e.g. 2048). None means no limit.\n",
    "           This does not affect the state returned.\"\"\"\n",
    "        assert max_tile is None or isinstance(max_tile, int)\n",
    "        self.max_tile = max_tile\n",
    "\n",
    "    # Implement gym interface\n",
    "    def step(self, action):\n",
    "        \"\"\"Perform one step of the game. This involves moving and adding a new tile.\"\"\"\n",
    "        logging.debug(\"Action {}\".format(action))\n",
    "        score = 0\n",
    "        done = None\n",
    "        info = {\n",
    "            'illegal_move': False,\n",
    "        }\n",
    "        try:\n",
    "            score = float(self.move(action))\n",
    "            if score > 0:\n",
    "                score = score\n",
    "                # score = math.log2(score)\n",
    "            if score < 0:\n",
    "                score = 0\n",
    "            self.score += score\n",
    "            assert score <= 2 ** (self.w * self.h)\n",
    "            self.add_tile()\n",
    "            done = self.isend()\n",
    "            reward = float(score)\n",
    "\n",
    "        except IllegalMove:\n",
    "            logging.debug(\"Illegal move\")\n",
    "            info['illegal_move'] = True\n",
    "            done = True\n",
    "            reward = self.illegal_move_reward\n",
    "            # reward=0\n",
    "\n",
    "        # print(\"Am I done? {}\".format(done))\n",
    "        info['highest'] = self.highest()\n",
    "\n",
    "        # Return observation (board state), reward, done and info dict\n",
    "        return stack(self.Matrix), reward, done, info\n",
    "    def reset(self):\n",
    "        self.Matrix = np.zeros((self.h, self.w), int)\n",
    "        self.score = 0\n",
    "\n",
    "        logging.debug(\"Adding tiles\")\n",
    "        self.add_tile()\n",
    "        self.add_tile()\n",
    "\n",
    "        return stack(self.Matrix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Implement 2048 game\n",
    "    def add_tile(self):\n",
    "        \"\"\"Add a tile, probably a 2 but maybe a 4\"\"\"\n",
    "        possible_tiles = np.array([2, 4])\n",
    "        tile_probabilities = np.array([0.9, 0.1])\n",
    "        val = self.np_random.choice(possible_tiles, 1, p=tile_probabilities)[0]\n",
    "        empties = self.empties()\n",
    "        assert empties.shape[0]\n",
    "        empty_idx = self.np_random.choice(empties.shape[0])\n",
    "        empty = empties[empty_idx]\n",
    "        logging.debug(\"Adding %s at %s\", val, (empty[0], empty[1]))\n",
    "        self.set(empty[0], empty[1], val)\n",
    "\n",
    "    def get(self, x, y):\n",
    "        \"\"\"Return the value of one square.\"\"\"\n",
    "        return self.Matrix[x, y]\n",
    "\n",
    "    def set(self, x, y, val):\n",
    "        \"\"\"Set the value of one square.\"\"\"\n",
    "        self.Matrix[x, y] = val\n",
    "\n",
    "    def empties(self):\n",
    "        \"\"\"Return a 2d numpy array with the location of empty squares.\"\"\"\n",
    "        return np.argwhere(self.Matrix == 0)\n",
    "\n",
    "    def highest(self):\n",
    "        \"\"\"Report the highest tile on the board.\"\"\"\n",
    "        return np.max(self.Matrix)\n",
    "\n",
    "    def board_total(self):\n",
    "        \"\"\"Calculate the total value of all tiles on the board.\"\"\"\n",
    "        return np.sum(self.Matrix)\n",
    "\n",
    "\n",
    "    def move(self, direction, trial=False):\n",
    "        \"\"\"Perform one move of the game. Shift things to one side then,\n",
    "        combine. directions 0, 1, 2, 3 are up, right, down, left.\n",
    "        Returns the maximum score that [would have] got from the move.\"\"\"\n",
    "        if not trial:\n",
    "            if direction == 0:\n",
    "                logging.debug(\"Up\")\n",
    "            elif direction == 1:\n",
    "                logging.debug(\"Right\")\n",
    "            elif direction == 2:\n",
    "                logging.debug(\"Down\")\n",
    "            elif direction == 3:\n",
    "                logging.debug(\"Left\")\n",
    "\n",
    "        changed = False\n",
    "        scores = []  # 修改为列表，用于存储每次移动得到的分数\n",
    "        dir_div_two = int(direction / 2)\n",
    "        dir_mod_two = int(direction % 2)\n",
    "        shift_direction = dir_mod_two ^ dir_div_two  # 0 for towards up left, 1 for towards bottom right\n",
    "\n",
    "        # Construct a range for extracting row/column into a list\n",
    "        rx = list(range(self.w))\n",
    "        ry = list(range(self.h))\n",
    "\n",
    "        if dir_mod_two == 0:\n",
    "            # Up or down, split into columns\n",
    "            for y in range(self.h):\n",
    "                old = [self.get(x, y) for x in rx]\n",
    "                (new, ms) = self.shift(old, shift_direction)\n",
    "                scores.append(ms)  # 添加到分数列表中\n",
    "                if old != new:\n",
    "                    changed = True\n",
    "                    if not trial:\n",
    "                        for x in rx:\n",
    "                            self.set(x, y, new[x])\n",
    "        else:\n",
    "            # Left or right, split into rows\n",
    "            for x in range(self.w):\n",
    "                old = [self.get(x, y) for y in ry]\n",
    "                (new, ms) = self.shift(old, shift_direction)\n",
    "                scores.append(ms)  # 添加到分数列表中\n",
    "                if old != new:\n",
    "                    changed = True\n",
    "                    if not trial:\n",
    "                        for y in ry:\n",
    "                            self.set(x, y, new[y])\n",
    "        if not changed:\n",
    "            raise IllegalMove\n",
    "            # 打印分数列表和最大分数\n",
    "\n",
    "        # 获取列表中的最大值作为 move_scores 返回\n",
    "        move_scores = max(scores) if scores else 0\n",
    "        # print(\"Scores from this move:\", scores)\n",
    "        # print(\"Maximum score from this move:\", move_scores)\n",
    "        return move_scores\n",
    "\n",
    "    def combine(self, shifted_row):\n",
    "        \"\"\"Combine same tiles when moving to one side. This function always\n",
    "           shifts towards the left. Also count the score of combined tiles.\"\"\"\n",
    "        move_score = 0\n",
    "        combined_row = [0] * self.size\n",
    "        skip = False\n",
    "        output_index = 0\n",
    "        for p in pairwise(shifted_row):\n",
    "            if skip:\n",
    "                skip = False\n",
    "                continue\n",
    "            combined_row[output_index] = p[0]\n",
    "            if p[0] == p[1]:\n",
    "                combined_row[output_index] += p[1]\n",
    "                move_score += p[0] + p[1]\n",
    "                # Skip the next thing in the list.\n",
    "                skip = True\n",
    "            output_index += 1\n",
    "        if shifted_row and not skip:\n",
    "            combined_row[output_index] = shifted_row[-1]\n",
    "\n",
    "        return (combined_row, move_score)\n",
    "\n",
    "    def shift(self, row, direction):\n",
    "        \"\"\"Shift one row left (direction == 0) or right (direction == 1), combining if required.\"\"\"\n",
    "        length = len(row)\n",
    "        assert length == self.size\n",
    "        assert direction == 0 or direction == 1\n",
    "\n",
    "        # Shift all non-zero digits up\n",
    "        shifted_row = [i for i in row if i != 0]\n",
    "\n",
    "        # Reverse list to handle shifting to the right\n",
    "        if direction:\n",
    "            shifted_row.reverse()\n",
    "\n",
    "        (combined_row, move_score) = self.combine(shifted_row)\n",
    "\n",
    "        # Reverse list to handle shifting to the right\n",
    "        if direction:\n",
    "            combined_row.reverse()\n",
    "\n",
    "        assert len(combined_row) == self.size\n",
    "        return (combined_row, move_score)\n",
    "\n",
    "    def isend(self):\n",
    "        \"\"\"Has the game ended. Game ends if there is a tile equal to the limit\n",
    "           or there are no legal moves. If there are empty spaces then there\n",
    "           must be legal moves.\"\"\"\n",
    "\n",
    "        # if self.max_tile is not None and self.highest() == self.max_tile:\n",
    "        #     return True\n",
    "\n",
    "        for direction in range(4):\n",
    "            try:\n",
    "                self.move(direction, trial=True)\n",
    "                # Not the end if we can do any move\n",
    "                return False\n",
    "            except IllegalMove:\n",
    "                pass\n",
    "        return True\n",
    "\n",
    "    def get_board(self):\n",
    "        \"\"\"Retrieve the whole board, useful for testing.\"\"\"\n",
    "        return self.Matrix\n",
    "\n",
    "    def set_board(self, new_board):\n",
    "        \"\"\"Retrieve the whole board, useful for testing.\"\"\"\n",
    "        self.Matrix = new_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Game2048Env()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型函数:\n",
    "def infer_model(model, env, threshold=1024, num_trials=100):\n",
    "    random_action_count = 0\n",
    "    model_action_count = 0\n",
    "    success_count = 0\n",
    "\n",
    "    for _ in range(num_trials):\n",
    "        s = env.reset()\n",
    "        last_s = None\n",
    "        actions_taken = []  # 初始化已尝试的动作列表\n",
    "\n",
    "        while True:\n",
    "            s_tensor = torch.FloatTensor(np.expand_dims(s, axis=0)).to(device)\n",
    "            if np.array_equal(last_s, s):\n",
    "                # 去除已尝试的动作\n",
    "                available_actions = [i for i in range(4) if i not in actions_taken]\n",
    "\n",
    "                # 如果没有剩余动作尝试，结束当前尝试\n",
    "                if not available_actions:\n",
    "                    break\n",
    "\n",
    "                # 选择一个新的动作\n",
    "                a = random.choice(available_actions)\n",
    "                actions_taken.append(a)  # 记录尝试过的动作\n",
    "                random_action_count += 1\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    logits = model(s_tensor)\n",
    "                    policy = F.softmax(logits, dim=1)\n",
    "                    m = Categorical(policy)\n",
    "                    a = m.sample().item()\n",
    "                model_action_count += 1\n",
    "                # 重置动作列表\n",
    "                actions_taken = []\n",
    "\n",
    "            last_s = np.array(s)\n",
    "            s_, r, done, info = env.step(a)\n",
    "            if done:\n",
    "                if env.highest() >= threshold:\n",
    "                    success_count += 1\n",
    "                break\n",
    "            s = s_\n",
    "    return success_count, random_action_count, model_action_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'NetLowReward' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 加载模型和相关数据\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 3\u001b[0m     model_data \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 提取模型\u001b[39;00m\n\u001b[1;32m      6\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m model_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'NetLowReward' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "# 加载模型和相关数据\n",
    "with open(\"Test.pkl\", \"rb\") as file:\n",
    "    model_data = pickle.load(file)\n",
    "\n",
    "# 提取模型\n",
    "loaded_model = model_data['model']\n",
    "# 如果模型保存时未被转移到 CPU，需确保其设备与当前环境一致\n",
    "loaded_model = loaded_model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 如果需要提取其他保存的信息，可以参考以下：\n",
    "standard_score = model_data['other_data']['standard_score']\n",
    "success_rate = model_data['other_data']['success_rate']\n",
    "rounds = model_data['other_data']['rounds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在 1000 局中测试模型的性能\n",
    "threshold_1024 = 1024\n",
    "threshold_2048 = 2048\n",
    "\n",
    "# 统计胜率\n",
    "success_count_1024, random_action_count_1024, model_action_count_1024 = infer_model(\n",
    "    loaded_model, env, threshold=threshold_1024, num_trials=1000\n",
    ")\n",
    "\n",
    "success_count_2048, random_action_count_2048, model_action_count_2048 = infer_model(\n",
    "    loaded_model, env, threshold=threshold_2048, num_trials=1000\n",
    ")\n",
    "\n",
    "# 打印结果\n",
    "print(f\"在 1000 局中达到 {threshold_1024} 的胜率: {success_count_1024 / 1000:.2%}\")\n",
    "print(f\"在 1000 局中达到 {threshold_2048} 的胜率: {success_count_2048 / 1000:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
